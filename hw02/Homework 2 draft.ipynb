{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "\n",
    "In this homework, we will explore a small dataset of 60 songs annotated with emotion using GEMS model. You received a folder with music files (one minute excerpts), a folder with automatically extracted chords that were parsed for you into chord root, chord triad type and chord extension, and emotional annotations in a CSV file.\n",
    "\n",
    "\n",
    "Prerequisites: install **pandas, scikit learn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "    where am i?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "PATH = os.getcwd() + '/'\n",
    "\n",
    "ch_path = PATH + 'chords/'\n",
    "mu_path = PATH + 'music/'\n",
    "\n",
    "print(f'PATH: {PATH}')\n",
    "print(f'chords path: {ch_path}')\n",
    "print(f'music path: {mu_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### <font color='red'> Exercise 1 (3 points). Design and extract some features based on the extracted chords (you might try number of unique chords or chord stems, consider summing up chord durations for a specific chord type, etc.) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "    load data\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "mu_ss = sorted(os.listdir( mu_path ))\n",
    "ch_ss = sorted(os.listdir( ch_path ))\n",
    "\n",
    "print(f'lenght sample space: { len(mu_ss) }')\n",
    "print(f'lenght chord sample space: { len(ch_ss) }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "    sample chords\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sample = np.random.choice( ch_ss ) \n",
    "\n",
    "print(f'sample: {sample}')\n",
    "\n",
    "example_chord_file = pd.read_csv( ch_path + sample )\n",
    "example_chord_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "    complete chords\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "ch_df = pd.DataFrame()\n",
    "\n",
    "for s in tqdm(ch_ss):\n",
    "    \n",
    "    if ch_df.empty:\n",
    "        \n",
    "        aux = pd.read_csv( ch_path + s )\n",
    "        aux['sample'] = s.replace('.csv', '')\n",
    "        \n",
    "        ch_df = aux\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        aux = pd.read_csv( ch_path + s )\n",
    "        aux['sample'] = s.replace('.csv', '')\n",
    "        \n",
    "        ch_df = pd.concat( [ ch_df, aux ], axis=0 )\n",
    "        \n",
    "miss = set([ x.replace('.csv', '') for x in ch_ss ]) - set(ch_df['sample'].unique())\n",
    "\n",
    "print(f'samples chords: {ch_df[\"sample\"].nunique()}')\n",
    "print(f'missing chords from: { miss }')\n",
    "\n",
    "ch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "    features\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(f'total number of chords: {ch_df[\"chord\"].nunique()}')\n",
    "print(f'total number of root chords: {ch_df[\"chord_root\"].nunique()}')\n",
    "\n",
    "ch_features = pd.DataFrame()\n",
    "\n",
    "# number of chords normalized with respect to the chords observed in the corpus\n",
    "\n",
    "ch_features = ch_df.groupby(['sample'])['chord'].nunique().reset_index().copy()\n",
    "ch_features['chord_norm'] = ch_features['chord'] / ch_df['chord'].nunique()\n",
    "\n",
    "# number of chords normalized with respect to the root chords observed in the corpus\n",
    "\n",
    "aux = ch_df.groupby(['sample'])['chord_root'].nunique().reset_index().copy()\n",
    "aux['chord_root_norm'] = aux['chord_root'] / ch_df['chord_root'].nunique()\n",
    "\n",
    "ch_features = ch_features.merge(aux, on='sample', how='right')\n",
    "\n",
    "# chords duration\n",
    "\n",
    "aux = ch_df.groupby(['sample', 'chord_root'])['chord_duration'].sum().reset_index(name='duration')\n",
    "aux['total'] = aux.groupby('sample')['duration'].transform('sum')\n",
    "aux['norm_duration'] = aux['duration'] / aux['total']\n",
    "aux = aux.pivot( index='sample', columns='chord_root', values='norm_duration' ).reset_index().fillna(0.0)\n",
    "aux.columns = [ x + '_d' if x != 'sample' else 'sample' for x in aux.columns ]\n",
    "\n",
    "ch_features = ch_features.merge(aux, on='sample', how='right')\n",
    "\n",
    "# chords representation\n",
    "\n",
    "aux = ch_df.groupby(['sample', 'chord_root']).size().reset_index(name='count')\n",
    "aux['total'] = aux.groupby('sample')['count'].transform('sum')\n",
    "aux['norm_count'] = aux['count'] / aux['total']\n",
    "aux = aux.pivot(index='sample', columns='chord_root', values='norm_count').reset_index().fillna(0.0)\n",
    "ch_features = ch_features.merge( aux, on='sample', how='right' )\n",
    "\n",
    "ch_features['sample'] = ch_features['sample'].astype('int')\n",
    "ch_features.sort_values(by=['sample'])\n",
    "\n",
    "features = [ x for x in ch_features if x not in ['sample'] ]\n",
    "\n",
    "print(f'features: \\n{features}')\n",
    "ch_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#feature_list=[]\n",
    "#chordfiles = os.listdir(\"chords\")\n",
    "#for filename in chordfiles: \n",
    "#    chords = pd.read_csv(os.path.join(\"chords\", filename), sep=',')\n",
    "    #... design at least 5 features based on chords here \n",
    "    \n",
    "#    feature1 = ...\n",
    "#    feature2 = ...\n",
    "#    feature3 = ...\n",
    "#    feature4 = ...\n",
    "#    feature5 = ...\n",
    "    \n",
    "#    song_file_id = filename.split(\".\")[0] + '.mp3'\n",
    "#    feature_list.append([song_file_id, feature1, feature2, feature3, feature4, feature5])\n",
    "\n",
    "# create a dataframe with your features\n",
    "#features = pd.DataFrame(feature_list, columns = ['filename','feature1', 'feature2', ... ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'> Exercise 2 (2 points). Cluster the music files based on your features. You can choose a different number of clusters. Then listen to the music and look at the cluster statistics and describe your clusters. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# we remove the file ids from cluster variables\n",
    "features_without_labels = ch_features[ features ].copy()\n",
    "\n",
    "# Choose your n_clusters here\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(features_without_labels)\n",
    "\n",
    "print(f'number of clusters: {len(set(kmeans.labels_))}')\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cluster_with_song_ids = pd.DataFrame(\n",
    "#    {'sample': ch_features['sample'].values,\n",
    "#     'KMeans_clusters': kmeans.labels_})\n",
    "\n",
    "#print(\"Cluster 1\")\n",
    "#print(cluster_with_song_ids[cluster_with_song_ids.KMeans_clusters==1][\"song_ids\"])\n",
    "\n",
    "# Reduce dimensionality with t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=30, learning_rate=200)\n",
    "df_tsne = tsne.fit_transform(ch_features[ features ].iloc[:, :-1])\n",
    "\n",
    "# Add t-SNE components to dataframe\n",
    "ch_features['tsne_x'] = df_tsne[:, 0]\n",
    "ch_features['tsne_y'] = df_tsne[:, 1]\n",
    "ch_features['kmeans_cluster'] = kmeans.labels_\n",
    "ch_features['kmeans_cluster'] = ch_features['kmeans_cluster'].astype('str')\n",
    "ch_features = ch_features.sort_values(by=['kmeans_cluster'])\n",
    "\n",
    "# histogram clusters\n",
    "fig = px.histogram(ch_features, x='kmeans_cluster')\n",
    "fig.show()\n",
    "\n",
    "# tsne viz\n",
    "fig = px.scatter(ch_features, x='tsne_x', y='tsne_y', color='kmeans_cluster')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "    feature viz\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for c in ch_features['kmeans_cluster'].unique():\n",
    "    \n",
    "    fig.add_trace( go.Histogram( x=ch_features[ ch_features['kmeans_cluster'] == c ]['chord_norm'], name=str(c) ) )\n",
    "    \n",
    "# Overlay both histograms\n",
    "fig.update_layout(barmode='overlay', title='chord')\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for c in ch_features['kmeans_cluster'].unique():\n",
    "    \n",
    "    fig.add_trace( go.Histogram( x=ch_features[ ch_features['kmeans_cluster'] == c ]['chord_root_norm'], name=str(c) ) )\n",
    "    \n",
    "# Overlay both histograms\n",
    "fig.update_layout(barmode='overlay', title='chord root')\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "    random sampling\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "for c in ch_features['kmeans_cluster'].unique():\n",
    "    \n",
    "    aux = ch_features[ ch_features['kmeans_cluster'] == c ]\n",
    "    sample = str(np.random.choice( aux['sample'].unique() )) + '.mp3'\n",
    "    \n",
    "    print(f'sample from cluster {c}: {sample}')\n",
    "    display(Audio( mu_path + sample, autoplay=False ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'> Listen to the songs in your clusters and describe the clusters that you found. What characteristics do they have? </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After fitting the data using k-means with three clusters, we found that one of them represents classical music, while clusters [1, 2] were more difficult to separate according to the heuristics. However, by observing the chords that describe each sample, it can be observed that there exists a threshold between the type of chords and the time each of them is used during the piece.**\n",
    "\n",
    "**I used t-SNE to project the feature space into two dimensions and it can be observed that the transition between labels is very smooth. Thus, we can compare the difference between the extreme clusters and it can be heard that the energy in the music goes from peaceful to a more energetic feel**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'> Exercise 3 (3 points). Now use your extracted features to predict one or more of the emotional dimensions of your choice. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_annotations = pd.read_csv(\"emotion_annotations.csv\")\n",
    "emotion_annotations = emotion_annotations.rename(columns={'song_id': 'sample'})\n",
    "emotion_annotations['sample'] = emotion_annotations['sample'].apply( lambda x: x.replace('.mp3', '') )\n",
    "\n",
    "ch_features['sample'] = ch_features['sample'].astype(str)\n",
    "features_with_emotion = emotion_annotations.merge(ch_features, on='sample', how='left').dropna()\n",
    "\n",
    "print(emotion_annotations.head())\n",
    "features_with_emotion.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = features_with_emotion\n",
    "\n",
    "fig = px.imshow(\n",
    "    corr_mat,\n",
    "    x=corr_mat.columns,\n",
    "    y=corr_mat.index\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Correlation Matrix',\n",
    "    width=500,\n",
    "    height=500,\n",
    "    xaxis_title='Features',\n",
    "    yaxis_title='Features'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'> Train a model of your choice and evaluate it's performance</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model here\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import shap\n",
    "import seaborn as sns\n",
    "\n",
    "shap.initjs()\n",
    "\n",
    "X = features_with_emotion[ features ].values\n",
    "y = features_with_emotion[ [ x for x in emotion_annotations if x not in ['sample'] ] ].values\n",
    "\n",
    "multi_regressor = MultiOutputRegressor(GradientBoostingRegressor(random_state=42))\n",
    "\n",
    "# perform k-fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# validation\n",
    "mse_scores = []\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    \n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    multi_regressor.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = multi_regressor.predict(X_test)\n",
    "    \n",
    "    mse_scores.append(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "# print the mean and standard deviation of the MSE scores\n",
    "print(\"mean MSE for 10 folds :\", np.mean(mse_scores))\n",
    "print(\"standard deviation for 10 folds:\", np.std(mse_scores))\n",
    "\n",
    "# fit all dataset\n",
    "model = multi_regressor.fit(X, y)\n",
    "\n",
    "# feature importance\n",
    "explainer = shap.KernelExplainer(model=model.predict, data=X, link=\"identity\")\n",
    "shap_values = explainer.shap_values(X=X)\n",
    "\n",
    "n = 0\n",
    "for i in [ x for x in emotion_annotations if x not in ['sample'] ]:\n",
    "    \n",
    "    print(f'----------- {i} -----------')\n",
    "    shap.summary_plot(shap_values=shap_values[ n ], features=features)\n",
    "    \n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'> What were your best features?  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The best features depends nin the context "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'> How long did it take you to do this homework? Do you have any comments on how to improve it? </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add your answer here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
